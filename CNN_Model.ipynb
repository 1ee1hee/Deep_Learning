{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Dataset과 ILSVRC 경진 대회"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet Dataset\n",
    "- https://www.image-net.org/\n",
    "- 웹상에서 수집한 약 1500만장의 라벨링된 고해상도 이미지로 약 22,000개 카테고리로 구성된 대규모 Image 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 대회\n",
    "- https://image-net.org/challenges/LSVRC/\n",
    "- 2010년 부터 2017 까지 진행된 컴퓨터 비전 경진대회\n",
    "- ImageNet의 이미지중 **1000개 카테고리 약 120만장의 학습용 이미지, 5만장의 검증 이미지, 15만장의 테스트 이미지를** 이용해 대회를 진행\n",
    "- 2012년 CNN기반 딥러닝 알고리즘인 **AlexNet**이 2위와 큰 차이로 우승하며 이후 딥러닝 알고리즘이 대세가 됨. 특히 2015년 우승한 ResNet은 0.036의 에러율을 보이며 우승\n",
    "- ILSVRC에서 우승하거나 좋은 성적을 올린 모델들이 컴퓨터 비전 분야 발전에 큰 역할을 해왔으며 이후 다양한 Computer Vision 분야의 네트워크 모델의 backbone으로 사용\n",
    "\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/6f381717-b787-43aa-aacf-8d5fee900147/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주요 CNN 모델\n",
    "- CNN 기반의 주요 모델들과 그 모델에 쓰인 주요 기법들\n",
    "    - VGGNet\n",
    "    - ResNet\n",
    "    - Mobilenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet(VGG16)\n",
    "- VGG(Visual Geometry Group)\n",
    "- ImageNet ILSVRC Challenge 2014에서 2등한 모델로 Simonyan and Zisserman(Oxford Univ.)에 의해 제안\n",
    "    - VGGNet이 준우승을 하긴 했지만, 구조의 간결함과 사용의 편이성으로 인해 1등한 GoogLeNet보다 더 각광받음\n",
    "    - 단순한 구조이지만 좋은 성능을 보여 이후 다양한 Computer Vision Network 모델에서 Feature 추출을 위한 Backbone Network으로 많이 사용\n",
    "- 네트워크 깊이가 어떤 영향을 주는 지 연구 하기 위해 설계된 네트워크로 모든 Layer에서 동일한 kernel size(3 x 3)의 필터를 사용했으며 filter(kernel)의 개수를 늘려가며 레이어를 쌓는 방식으로 구성\n",
    "    - 11 layer, 13 layer, 16 layer, 19 layer의 네트워크를 테스트함\n",
    "        - 이 중 VGG-16 모델이 2014년도 ILSVRC 대회에 참가한 모델\n",
    "    - 19 layer의 성능이 16 layer보다 크게 나아지지 않았고 21개 Layer를 쌓는 모델은 성능이 떨어짐\n",
    "- Filter의 수를 64, 128, 256, 512 두 배씩 키움\n",
    "- 모든 layer들에 **$3 \\times 3$ filter, stride=1, same padding의 Convolution Layer**와 **$2\\times 2$, stride=2의 MaxPooling** 사용\n",
    "    - 이전 AlexNet이 5 X 5 필터를 사용했는데 VGG16은 3 X 3 필터의 Layer를 두개 연속으로 연결\n",
    "        - **3 x 3 필터 두개를 쌓는 것이 5 x 5  하나를 사용하는 보다 더 적은 파라미터를 사용하며 성능이 더 좋음**\n",
    "    - Feature map의 사이즈를 convolution layer가 아닌 Max Pooling 을 사용해 줄여줌\n",
    "- VGG16의 단점은 마지막에 분류를 위해 Fully Connected Layer 3개를 붙여 파라미터 수가 너무 많아 짐. 약 1억 4천만 개의 parameter(가중치)중 1억 2천만개 정도가 Fully Connected Layer의 파라미터 임\n",
    "- 구조\n",
    "\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/4ace45ca-637a-4bc5-a5f4-5a635e0489ec/image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet(Residual Networks)\n",
    "- 2015년 마이크로소프트 리서치 팀에서 제안한 신경망구조로 잔차 모듈(Residual module)과 skip connection 이라는 구조가 사용됨\n",
    "- **Skip connection(Shortcut connection)기법을 이용해 Layer수를 획기적으로 늘린 CNN 모델**로 ILSVRC 2015년 대회에서 우승\n",
    "\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/99374fc0-4e32-44f0-a09d-505718548300/image.png)\n",
    "\n",
    "- \"레이어를 깊게 쌓으면 성능이 더 좋아 지지 않을까?\"라는 가설에서 시작\n",
    "    - Layer를 깊게 쌓으면 비선형이 더 많이 추가 됨. 그러면 더 많은 특성들을 추출할 수 있기 때문에 네트워크 모델의 성능이 더 좋아질 수 있다\n",
    "    - 실제는 Test셋 뿐만 아니라 Train Set에서도 성능이 좋지 않음\n",
    "- Train set에서도 성능이 나쁘게 나온 것은 최적화 문제로 보고, 레이어를 깊게 쌓으면 최적화 하기가 어렵다고 생각함\n",
    "    - Layer를 깊게 쌓으면 weight들이 더 많이 생기므로 최적화가 어려워짐\n",
    "\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/7d618ed9-81f5-4187-9da7-2bd30ceffcfc/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/7177f404-8eee-4f84-9f76-5f0cdc42741c/image.png)\n",
    "\n",
    "- 입력값을 그래로 출력하는 identity block을 사용하면 성능이 떨어지지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "- Residual block\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/1b3e56c8-6e40-44ff-ace9-3d35aba4fc76/image.png)\n",
    "\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/241631d4-4ab9-4ecb-9e15-f90e9e988114/image.png)\n",
    "\n",
    "- 기존 Layer들의 목표는 입력값인 X를 출력값인 Y로 최적의 매핑할 수 있는 함수 H(X)를 찾는 것임. 따라서 H(X) - Y가 최소값이 되는 방향으로 학습을 진행하면서 H(X)를 찾음. 그런데 레이어가 깊어지면서 최적화에 어려움으로 성능이 떨어지는 문제가 발생\n",
    "- ResNet은 layer를 통과해서 나온 값이 **입력값과 동일하게 만드는 것을 목표로 하는 Identity block**을 구성함\n",
    "- Identity block은 입력값 X를 레이어를 통과시켜서 나온 Y에 입력값 X를 더해서 합치도록 구성\n",
    "$$\\large H(x) = F(x) + x\\\\x: input,\\;H(x): output,\\;F(x): layer통과값$$ \n",
    " \n",
    " \n",
    "- 목표는 $H(x)$(레이어통과한 값) 가 input인 x와 동일한 것이므로 F(x)를 0으로 만들기 위해 학습을 함\n",
    "- $F(x)$는 **잔차(Residual)** 가 된다. 그리고 잔차인 $F(x)$가 0이 되도록 학습하는 방식이므로 Residual Learning이라고 한다\n",
    "- 입력인 x를 직접 전달하는 것을 **shortcut connection** 또는 **identity mapping** 또는 **skip connection** 이라고 함\n",
    "    - 이 shortcut은 파라미터 없이 단순히 값을 더하는 구조이므로 연산량에 크게 영향이 없음\n",
    "- 그리고 Residual을 찾는 레이어를 **Residual Block, Identity Block** 이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능향상\n",
    "- $H(x) = F(x) + x$ 을 $x$에 대해 미분하면 최소한 1이므로 Gradient Vanishing 문제를 해결함.\n",
    "    - 전달 된 gradient가 앞쪽(botton) layer에 그대로 전달되 gradient가 소실되는 문제가 해결됨\n",
    "    - x + y 를 y에 대해 미분하면 1\n",
    "- 잔차학습이라고 하지만 Residual block 은 Convolution Layer와 Activation Layer로 구성되어 있기 때문에 이 Layer를 통과한 Input으로 부터 Feature map을 추출하는 과정은 진행되며 레이어가 깊어 다양한 더욱 풍부한 특성들을 추출하게 되어 성능이 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 구조\n",
    "![image](https://www.researchgate.net/profile/Shreya-Ravi-2/publication/342352881/figure/fig7/AS:905070317146112@1592796987077/ResNet-Architecture.ppm)\n",
    "\n",
    "- Residual block들을 쌓는 구조\n",
    "    - 일반 Convolution layer(backbone)을 먼저 쌓고 Identity(Residual) block들을 계속 쌓는다\n",
    "- 모든 Identity block은 두개의 3X3 conv layer로 구성됨\n",
    "- 일정 레이어 수별로 filter의 개수를 두배로 증가시켜 stride를 2로 하여 downsampling 함(Pooling Layer는 Identity block의 시작과 마지막에만 적용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/6155a0e3-7b18-4b74-b041-b514d395d252/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet\n",
    "### 개요\n",
    "스마트폰이나 마이크로 디바이스와 같은 저성능 컴퓨팅 환경에서 실행할 수 있도록 하기 위해 딥려닝 네트워크를 가볍게 구성하는 방법(경량 네트워크 - Small Deep Neural Network)에 대한 연구가 활성화됨. 저성능 환경에서 실행되기 위해서는 다음과 같은 사항을 만족시켜야 함\n",
    "- 적은 연산량(낮은 계산의 복잡도)을 통한 빠른 실행\n",
    "- 작은 모델 크기\n",
    "- 충분히 납득할 만한 정확도\n",
    "- 저전력 사용\n",
    "즉 기존의 성능만을 신경쓴 모델보다 **적은 연산량으로 빠르게 추론할 수 있어야 하고 납득할 수 있는 성능을 내야 함**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Deep Neural Network위한 방법\n",
    "- **Channel Reduction**\n",
    "    - Channel의 개수를 줄인다\n",
    "- **Distillation & Compression**\n",
    "    - Distillation\n",
    "        - 큰 모델(Teacher Model)이 미리 학습한 정보(Knowledge)를 작은 모델에 전달하여 성능을 향상시키는 기법\n",
    "    - Compression\n",
    "         - 모델 가지치기(Model Pruning - 중요도가 떨어지는 파라미터를 0으로해 크기를 줄임)등의 기법들을 이용해 네트워크가 크기를 줄이는 기법\n",
    "- **Depthwise Seperable Convolution**\n",
    "    - Depthwise Convolution과 Pointwise Convolution Layer를 연결한 모델을 구성하여 연산량을 줄임\n",
    "-  Remove Fully-Connected Layers\n",
    "    - Fully Connected(Dense) Layer들을 Convolution Layer로 대체. Convolution Layer는 파라미터를 공유하므로 파라미터 개수가 줄어들어 Network가 경량화 됨\n",
    "- Kernel Reduction\n",
    "    - Kernel(Filter)의 크기를 줄여서 연산량과 파라미터의 수를 줄임\n",
    "- Early Spaced Downsampling\n",
    "    - CNN은 Layer block(Conv, pooling)을 거칠수록 output의 size를 줄이는 downsampling을 하게 됨. Downsampling을 **초반(bottom)에 크게 하면 네트워크의 크기는 줄어들지만 이미지의 특성을 많이 잃어버리게 되어 성능이 낮아지고, 후반(top)에 많이 하게 되면 성능은 좋아지지만 네트워크의 크기는 크게 줄지 않게 된다.** 그래서 전체적으로 균일하게 DownSampling을 하되 그 시점을 튜닝을 통해 찾는다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Mobilnet은 위의 기법 중 Channel Reduction, Distillation & Compression, Depthwise Seperable Convolution을 적용하여 경량 네트워크를 구현한 모델이다`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depthwise Separable Convolution\n",
    "- Depthwise Convolution 구조에 Pointwise Convolution 구조를 합쳐 기존 Convolution layer보다 연산량을 줄여서 속도를 증가시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depthwise Convolution\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/0a9f8780-d491-4a3b-bf61-dcfdf61d8c5d/image.png)\n",
    "\n",
    "표준 Convolution은 한개의 Filter가 Input의 채널 전체에 대해 Convolution 연산을 한다. 그에 비해 **Depthwise Convolution은 한개의 Filter는 한개의 Channel에만 Convolution 연산을 한다**\n",
    "\n",
    "위 그림을 보면 Input Data의 shape이 ($D_F$, $D_F$, $M$)일 경우 ($D_k$,$D_k$,$1$) shape의 필터 M개를 생성한다. 그리고 한개의 필터가 하나의 Channel(M개)에 대해 Convolution 연산을 처리한다. 그래서 필터를 거친 Output은 ($D_G$, $D_G$, $M$)의 shape이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Convolution\n",
    "![image](https://gaussian37.github.io/assets/img/dl/concept/dwsconv/5.png)\n",
    "\n",
    "- Pointwise Convolution은 1 X 1 필터를 이용해 Convolution 연산을 처리한다\n",
    "- Pointwise Convolution을 사용하는 구조를 Bottlenet 이라 함\n",
    "- 이 구조는 height와 width를 유지하면서 Channel의 크기를 조절하기 위해 사용\n",
    "\n",
    "위 이미지를 보면 Input Shape이 ($D_G$, $D_G$, $M$) 일때 ($1$, $1$, $M$) shape의 필터를 $N$개 사용하여 Convolution 연산을 한다. 표준 Convolution연산을 진행하므로 filter의 channel 크기는 input과 동일한 $M$개이며 필터의 개수인 $N$으로 Output의 channel을 결정한다.  그래서 Output의 결과는 ($D_G$, $D_G$, $N$) 이 된다. 1 X 1 필터를 사용하므로 출력 결과의 width, height는 변경되지 않는다. (stride를 1로 지정)  \n",
    "\n",
    "위 두단계의 convolution연산을 이어서 진행 하여 표준 Convolution에 비해 **Depthwise convolution으로 연산량을 줄이고 pointwise convolution으로 출력 결과의 shape은 동일하게** 만들어 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표준 Convolution과 Depthwise Separable Convolution의 연산량 비교\n",
    "### 표준 Convolution 연산량\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/a5e675fc-b949-4339-9214-484356153f6f/image.png)\n",
    "\n",
    "#### 표준 Convolution 연산\n",
    "- Input Image shape: ($D_F$, $D_F$, $M$)\n",
    "- Filter shape: ($D_K$, $D_K$, $M$) X N개\n",
    "    - channel은 input의 channel과 동일\n",
    "- Convolution연산 이동 횟수:  ($D_G$, $D_G$)\n",
    "- Output shape: ($D_G$, $D_G$, $N$)\n",
    "\n",
    "![image](https://velog.velcdn.com/images/lee1066515/post/7d0383b8-fe29-48bf-9036-6156963004d3/image.gif)\n",
    "\n",
    "- **연산량**\n",
    "    - 한번의 연산량: $D_k^2 \\times M$\n",
    "    - 하나의 필터의 연산량: $D_G^2 \\times D_k^2 \\times M$\n",
    "        - 가로, 세로방향으로 $D_G$ 만큼 이동하므로 한번 연산량에 $D_G^2$ 곱한 만큼 연산한다.\n",
    "    - N개의 Filter(Kernel)의 연산량: $N \\times D_G^2 \\times D_k^2 \\times M$\n",
    "\n",
    "- **Depthwise Separable Convolution**은 출력결과 형태(shape)은 동일하면서 연산량을 줄이는 것이 목표이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depthwise Separable Convolution 연산량\n",
    "#### Depthwise Convolution 연산량\n",
    "- 한번의 연산량: $D_K^2$ \n",
    "    - Filter한개가 하나의 Channel과 연산한다.\n",
    "- 1개 Channel에 대한 연산량: $D_G^2 \\times D_K^2$ \n",
    "    - $D_G$가 가로,세로방향 이동 횟수이다.\n",
    "- M개의 Filter의 연산량: $M \\times D_G^2 \\times D_K^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pointwise Convolution 연산량\n",
    "- 한번의 연산량: M\n",
    "    - 1 x 1 필터이므로 한번 연산은 channel 개수만큼 연산한다.\n",
    "- 1개 Filter(Kernel)의 연산량: $D_G^2 \\times M$\n",
    "- N개 필터의 연산량: $N \\times D_G^2 \\times M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depthwise Separable Convolution 연산량\n",
    "- **Depthwise Convolution연산량 + Pointwise Convolution 연산량**\n",
    "$$\n",
    "M \\times D_G^2 \\times D_K^2 + N \\times D_G^2 \\times M\\\\\n",
    "= \\\\\n",
    "M \\times D_G^2(D_K^2 + N)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표준 Convolution과 Depthwise Separable Convolution 연산량 비교\n",
    "$$\n",
    "\\cfrac{Depthwise Separable}{표준 Convolution} \\\\\n",
    "= \\\\\n",
    "\\cfrac{M \\times D_G^2(D_K^2 + N)}{N \\times D_G^2 \\times D_K^2 \\times M} \\\\\n",
    "= \\\\\n",
    "\\cfrac{D_K^2 + N}{D_K^2 \\times N} \\\\\n",
    "= \\\\\n",
    "\\cfrac{1}{N} + \\cfrac{1}{D_K^2}\n",
    "$$\n",
    "- $D_K$: Filter의 height, width\n",
    "- $D_G$: Convolution의 이동 횟수. Output(Feature map)의 height, width\n",
    "- $M$: Input의 channel\n",
    "- $N$: Filter 개수\n",
    "\n",
    "#### **`필터의 개수(N)이 1024이고 필터 크기($D_K$)가 3인경우. 즉 (3,3) 필터 1024개를 사용한 경우 연산량이 $\\cfrac{1}{9}$ 정도 줄어든다`**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
